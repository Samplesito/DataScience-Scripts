{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import pickle\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1 = df.drop([\"UselessColumn1\",\"UselessColumn2\"],axis=1)\n",
    "df_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_v1[\"target\"]\n",
    "X = df_v1.copy()\n",
    "X = X.drop(\"target\",axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {\"max_depth\":[4,5,6,7,8],\n",
    "             \"min_child_weight\":[1,2,3,4,5],\n",
    "             \"learning_rate\":[0.05,0.1,0.2,0.3],\n",
    "             \"n_estimators\":[75,100,125]\n",
    "             }\n",
    "xgb = XGBClassifier(objective=\"binary:logistic\" ,random_state=0)\n",
    "scoring = {\"accuracy\",\"precision\",\"recall\",\"f1\"} \n",
    "xgb_cv = GridSearchCV(xgb, cv_params, scoring=scoring, cv=5,refit=\"f1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pickle & save\n",
    "#Saving the model since it might use a lot of time to train\n",
    "import pickle\n",
    "path = \"../Proyectos DS/\"\n",
    "with open(path+\"xgb_cv_model_p.pickle\", \"wb\") as to_write:\n",
    "    pickle.dump(xgb_cv, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle Load\n",
    "#to open a pickle...\n",
    "with open(path+\"xgb_cv_model_p.pickle\", \"rb\") as to_read:\n",
    "    xgb_cv = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can arrange the results in a dataframe, as a function for reusing later\n",
    "results = pd.DataFrame(columns=[\"Model\",\"F1\",\"Recall\",\"Precision\",\"Accuracy\"])\n",
    "def make_results(model_name, model_object):\n",
    "    #Note: Model_Name is just a string for the name.\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "    #Calling just the one with highest mean f1\n",
    "    best_estimator_results = cv_results.iloc[cv_results[\"mean_test_f1\"].idxmax(),:]\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "\n",
    "    data = pd.DataFrame()\n",
    "    data = data.append({\"Model\": model_name, \"F1\": f1, \"Precision\": precision, \"Accuracy\": accuracy}, ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_results = make_results(\"XGBoost CV\", xgb_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_preds = xgb_cv.predict(X_test)\n",
    "print(\"F1 score for test data:\", f1_score(y_test, xgb_cv_preds))\n",
    "\n",
    "print(\"Recall score for test data:\", recall_score(y_test, xgb_cv_preds))\n",
    "\n",
    "print(\"Precision score for test data:\", precision_score(y_test, xgb_cv_preds))\n",
    "\n",
    "print(\"Accuracy score for test data:\", accuracy_score(y_test, xgb_cv_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a confusion matrix function to stop doing it all the time.\n",
    "def conf_matrix_plot(model, x_data, y_data):\n",
    "    model_pred = model.predict(x_data)\n",
    "    cm = confusion_matrix(y_data, model_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=model.classes_ )\n",
    "    disp.plot()\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_plot(xgb_cv,X_test,y_test)\n",
    "plot_importance(xgb_cv.best_estimator_);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
